{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin\\Dropbox\\DH\\Eigene\\ZeitromanGBVplusDLA\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Titel: 442\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "counter = 0\n",
    "books = {}\n",
    "\n",
    "\n",
    "### READING prefiltered DLA&DNB-data (all appearences of \"zeitroman\" / \"zeit-roman\" )\n",
    "with open(r\"ZeitromanDLAplusGBV.csv\") as f:\n",
    "    rd = csv.DictReader(f, delimiter=';')\n",
    "    \n",
    "    for row in rd:\n",
    "        counter += 1\n",
    "        #key = row[0]\n",
    "        key = row.pop('risn', None) # WICHTIG: hier Kopf der Nummerierung einfÃ¼gen\n",
    "        if key in books:\n",
    "            print(\"key ist doppelt\")\n",
    "            break\n",
    "            pass\n",
    "        if counter > 1000:\n",
    "            break\n",
    "            pass\n",
    "        books[key] = row\n",
    "#print(books)\n",
    "\n",
    "count_fictions = len(books)\n",
    "print('Anzahl der Titel:', count_fictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `author`, `title`, `date` for leftover books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(b):\n",
    "    \n",
    "    title_id = b\n",
    "    try:\n",
    "        author = books[b]['XX_PE_listview_title_PE0100']\n",
    "        #author = author.split('(', 1)[0]\n",
    "        #author = author.split(';', 1)[0]\n",
    "\n",
    "    except:\n",
    "        author = None\n",
    "        pass\n",
    "        \n",
    "    title = books[b]['TITREG']\n",
    "    \n",
    "    try:\n",
    "        sub_title = books[b]['A0335']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        title_without_sub = books[b]['A0331'] #funzt nur bei DLA-Daten\n",
    "    except:\n",
    "        title_without_sub = title.rsplit('---', 1)[0]\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        date = books[b]['AA425']\n",
    "        if len(date) == 0:\n",
    "            date = books[b]['A0425']\n",
    "            #print('USED A0425')\n",
    "        if len(date) == 0:\n",
    "            date = books[b]['A0427']\n",
    "            dates_list = re.findall(\"[0-9]{4,}\", date)\n",
    "            dates_list = [int(x) for x in dates_list]\n",
    "            dates_list.sort\n",
    "            date = str(dates_list[0])\n",
    "            #print('USED A0427')\n",
    "        date = ''.join([c for c in date if c.isnumeric()])\n",
    "        if len(date) > 4:\n",
    "            date = date[:4]\n",
    "        date = int(date)\n",
    "        \n",
    "    except:\n",
    "        date = None\n",
    "        pass\n",
    "            \n",
    "    \n",
    "    try:\n",
    "        edition = books[b]['A0403']\n",
    "    except:\n",
    "        edition = None\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        location = str.lower(str(books[b]['A0410']))\n",
    "    except:\n",
    "        location = None\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        publishing_house = str.lower(str(books[b]['A0412']))\n",
    "    except:\n",
    "        publishing_house = None\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        pages = str.lower(str(books[b]['A0433']))\n",
    "        number_of_pages = pages.split('s', 1)[0]    \n",
    "       \n",
    "    except:\n",
    "        number_of_pages = None\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        genre_by_librarian = books[b]['A0712']\n",
    "    except:\n",
    "        genre_by_librarian = None\n",
    "        pass\n",
    "\n",
    "    if sub_title:\n",
    "        return {'author': author,\n",
    "                'title': title,\n",
    "                'date': date,\n",
    "                'subtitle': sub_title,\n",
    "                'title_without_sub': title_without_sub,\n",
    "                'edition': edition,\n",
    "                'location': location,\n",
    "                'publishing-house': publishing_house,\n",
    "                'pages': number_of_pages,\n",
    "                'genre-by-librarian': genre_by_librarian,\n",
    "                'title_id': title_id}\n",
    "    else:\n",
    "        return {'author': author,\n",
    "                'title': title,\n",
    "                'date': date,\n",
    "                'title_without_sub': title_without_sub,\n",
    "                'edition': edition,\n",
    "                'location': location,\n",
    "                'publishing-house': publishing_house,\n",
    "                'pages': number_of_pages,\n",
    "                'genre-by-librarian': genre_by_librarian,\n",
    "                'title_id': title_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove everything that isn't first edition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 of 442 German fiction books were first editions\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sifted_books = {} \n",
    "for b in books:\n",
    "        \n",
    "    try:\n",
    "        desc = books[b]['A0403']\n",
    "        desc = desc.replace('[', '').replace(']', '')\n",
    "        \n",
    "    except:\n",
    "        sifted_books[b] = books[b]\n",
    "        continue\n",
    "\n",
    "    if desc[0:2] == '1.':\n",
    "        sifted_books[b] = books[b]\n",
    "        continue\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    pattern = re.compile(r'([Nn]ova|[Nn]ouv|[Bb]earb|Gek|[Ee]rw|[Ff]aks|[Ss]chul|[Mm]onumental|[Ff]eldpost|[Bb]linden|[Rr]epr|[Nn]eu|[Vv]olksausgabe|[Ll]imited|\\[.+\\]|\\[.+\\]|[Aa]ktualisiert|[Nn]achdr|[Kk]ult|[Ee]xclusiv|[Kk]orrigiert|[Ss]tudien|[Dd]urchges)')\n",
    "    pattern2 = re.compile(r'([023456789]{1,2}\\.\\s)')\n",
    "    pattern_non = re.compile(r'([Tt]sd|[Tt]aus\\.|[Tt]ausend|[Ee]rstausg|[1]\\.\\s[Aa]usg|[1]\\.\\s[Aa]ufl|[1]\\.\\s[Aa]usg)|[Dd]er\\sendg')\n",
    "    \n",
    "    if len(re.findall(pattern, desc)) > 0:\n",
    "        #print(desc)\n",
    "        continue\n",
    "        \n",
    "    if len(re.findall(pattern2, desc)) > 0 and len(re.findall(pattern_non, desc)) == 0:\n",
    "        #print(desc)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        num = int(desc.strip()[0])\n",
    "        if num > 1 and len(re.findall(pattern_non, desc)) == 0:\n",
    "            #print(desc)\n",
    "            continue\n",
    "        try:\n",
    "            num1 = int(desc.strip()[1])\n",
    "            if num1 > 1 and len(re.findall(pattern_non, desc)) == 0:\n",
    "                #print('Num1 =', num1)\n",
    "                #print(desc)\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    sifted_books[b] = books[b]\n",
    "    #sifted_books.append(b)\n",
    "#print(dict(list(sifted_books.items())[0:2]))\n",
    "print('{} of {} German fiction books were first editions'.format(len(sifted_books), count_fictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 of 375 German fiction first editions were not translations\n"
     ]
    }
   ],
   "source": [
    "sifted_books2 = {} \n",
    "desc = ''\n",
    "\n",
    "for b in sifted_books:\n",
    "        \n",
    "    try:\n",
    "        desc = sifted_books[b]['A0359'] + ' ' + sifted_books[b]['A0335'] + ' ' + sifted_books[b]['A0501']\n",
    "        #desc = desc.replace('[', '').replace(']', '')\n",
    "        \n",
    "    except:\n",
    "        sifted_books2[b] = sifted_books[b]\n",
    "        continue\n",
    "\n",
    "    pattern245 = re.compile(r'(=|([^\\s]+)bers\\.|([^\\s]+)bersetzt|([^\\s]+)bersetzung|([^\\s]+)bertr\\.|([^\\s]+)bertragen|([^\\s]+)bertragung)|[Tr]ansl|[Tr]aduz|[Tr]aduc|[Tt]raduit|[Tt]radot|[Tt]rad\\.|[Oo]versat|[Pp]ereved|([^\\s]+)versatt|[Pp]erekl|[Pp]rzet([^\\s]+)umacz|p([^\\s]+)elo([^\\s]+)eno|[Pp]reved|[Pp]rze([^\\s]+).|[Pp]rze([^\\s]+)o([^\\s]+)y([^\\s]+)|[Oo]versat|[Kk]([^\\s]+)([^\\s]+)nnet|[Pp]rev|[Ll]eford([^\\s]+)tott|[Pp]erev|[Pp]rzek([^\\s]+)ad|[Tt]olkning')\n",
    "    pattern_nicht = re.compile(r'([^\\s]+)bersetzungen')\n",
    "    \n",
    "    if len(re.findall(pattern245, desc)) > 0 and len(re.findall(pattern_nicht, desc)) == 0:\n",
    "        #print(desc, '\\n')\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    sifted_books2[b] = sifted_books[b]\n",
    "\n",
    "#print(dict(list(sifted_books2.items())[0:2]))\n",
    "print('{} of {} German fiction first editions were not translations'.format(len(sifted_books2), len(sifted_books)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Delete duplicates\n",
    "\n",
    "Function to check whether authors or dates are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_authors(a1, a2):\n",
    "\n",
    "    a1str = a1.strip()\n",
    "    a2str = a2.strip()\n",
    "    \n",
    "    if (len(a1str) == 0 or a1 == None) and (len(a1str) == 0 or a2 == None):\n",
    "        return True ### wenn beide Titel keine Autoren haben, als Duplikate behandeln?\n",
    "      \n",
    "    a1 = ''.join([x for x in a1 if x not in punctuation])\n",
    "    a2 = ''.join([x for x in a2 if x not in punctuation])\n",
    "    \n",
    "    a1_words = a1.split()\n",
    "    a2_words = a2.split()\n",
    "    #print(\"AAA1: \", a1, \"AAA2:\", a2)\n",
    "    \n",
    "    count = 0\n",
    "    for w in a2_words:\n",
    "        if w in a1_words:\n",
    "            count += 1\n",
    "            \n",
    "    if count >= 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_dates(d1, d2):\n",
    "    if d1 == None and d2 != None:\n",
    "        return 'check'\n",
    "    elif d2 == None and d1 != None:\n",
    "        return 'current'\n",
    "    elif d1 == None and d2 == None:\n",
    "        return 'check'\n",
    "    elif d2 > d1:\n",
    "        return 'current'\n",
    "    else:\n",
    "        return 'check'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove if author and title are the same, keep earlier date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 of 375 first edition German novels that were no translations are not duplicates\n"
     ]
    }
   ],
   "source": [
    "no_duplicates = {}\n",
    "\n",
    "to_del = []\n",
    "current_title_without_sub = \"\"\n",
    "check_b_title_without_sub = \"\"\n",
    "infos = {}\n",
    "\n",
    "for b in sifted_books2:\n",
    "    current_b = get_info(b)\n",
    "    current_title_without_sub = current_b['title_without_sub']\n",
    "    no_append = False\n",
    "    \n",
    "    for i, n in enumerate(no_duplicates):\n",
    "        if not (i in infos):\n",
    "            infos[i] = get_info(n) \n",
    "\n",
    "        \n",
    "        check_b = infos[i] \n",
    "        check_b_title_without_sub = check_b['title_without_sub']\n",
    "        \n",
    "        if current_title_without_sub == check_b_title_without_sub:\n",
    "            same_author = check_authors(current_b['author'], check_b['author'])\n",
    "            if same_author == True:\n",
    "                date = check_dates(current_b['date'], check_b['date'])\n",
    "                if date == 'current':\n",
    "                    no_append = False\n",
    "                    to_del.append(n)\n",
    "                else:\n",
    "                    no_append = True\n",
    "                    break\n",
    "                    \n",
    "    if no_append == False:\n",
    "        no_duplicates[b] = sifted_books2[b]\n",
    "        \n",
    "for i, z in enumerate(list(set(to_del))):\n",
    "    del no_duplicates[z]\n",
    "    \n",
    "print('{} of {} first edition German novels that were no translations are not duplicates'.format(len(no_duplicates), len(sifted_books2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 of 442 total records (DLA & DNB, fictions) were kept\n"
     ]
    }
   ],
   "source": [
    "print('{} of {} total records (DLA & DNB, fictions) were kept'.format(len(no_duplicates), count_fictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('no_duplicate.pkl', 'wb')\n",
    "pickle.dump(no_duplicates, filehandler, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_csv = [get_info(x) for x in no_duplicates]\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('ZeitromanDLAplusGBV_automatisch_gefiltert.csv', 'w', encoding='utf8') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, delimiter=';', lineterminator='\\n', fieldnames=['author', 'title', 'subtitle', 'title_without_sub', 'edition', 'genre', 'date', 'location', 'publishing-house', 'pages', 'genre-by-librarian', 'title_id'])\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(for_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Jahr  Untertitel.Zeitroman\n",
      "72   1800                     0\n",
      "73   1801                     0\n",
      "74   1802                     0\n",
      "75   1803                     0\n",
      "76   1804                     0\n",
      "77   1805                     0\n",
      "78   1806                     0\n",
      "79   1807                     0\n",
      "80   1808                     0\n",
      "81   1809                     0\n",
      "82   1810                     0\n",
      "83   1811                     0\n",
      "84   1812                     0\n",
      "85   1813                     0\n",
      "86   1814                     0\n",
      "87   1815                     0\n",
      "88   1816                     0\n",
      "89   1817                     0\n",
      "90   1818                     0\n",
      "91   1819                     0\n",
      "92   1820                     0\n",
      "93   1821                     0\n",
      "94   1822                     0\n",
      "95   1823                     0\n",
      "96   1824                     0\n",
      "97   1825                     0\n",
      "98   1826                     0\n",
      "99   1827                     0\n",
      "100  1828                     0\n",
      "101  1829                     0\n",
      "102  1830                     0\n",
      "103  1831                     0\n",
      "104  1832                     0\n",
      "105  1833                     0\n",
      "106  1834                     0\n",
      "107  1835                     0\n",
      "108  1836                     0\n",
      "109  1837                     0\n",
      "110  1838                     0\n",
      "111  1839                     0\n",
      "112  1840                     0\n",
      "113  1841                     0\n",
      "114  1842                     0\n",
      "115  1843                     0\n",
      "116  1844                     0\n",
      "0    1845                     1\n",
      "117  1846                     0\n",
      "1    1847                     1\n",
      "118  1848                     0\n",
      "119  1849                     0\n",
      "120  1850                     0\n",
      "2    1851                     1\n",
      "121  1852                     0\n",
      "122  1853                     0\n",
      "123  1854                     0\n",
      "124  1855                     0\n",
      "3    1856                     1\n",
      "125  1857                     0\n",
      "4    1858                     1\n",
      "126  1859                     0\n",
      "127  1860                     0\n",
      "128  1861                     0\n",
      "129  1862                     0\n",
      "130  1863                     0\n",
      "5    1864                     1\n",
      "131  1865                     0\n",
      "132  1866                     0\n",
      "133  1867                     0\n",
      "134  1868                     0\n",
      "6    1869                     1\n",
      "135  1870                     0\n",
      "7    1871                     1\n",
      "8    1872                     2\n",
      "9    1873                     2\n",
      "10   1874                     3\n",
      "11   1875                     2\n",
      "12   1876                     1\n",
      "136  1877                     0\n",
      "137  1878                     0\n",
      "138  1879                     0\n",
      "13   1880                     1\n",
      "139  1881                     0\n",
      "14   1882                     1\n",
      "140  1883                     0\n",
      "15   1884                     2\n",
      "141  1885                     0\n",
      "16   1886                     2\n",
      "17   1887                     2\n",
      "18   1888                     2\n",
      "19   1889                     1\n",
      "20   1890                     1\n",
      "142  1891                     0\n",
      "143  1892                     0\n",
      "21   1893                     1\n",
      "22   1894                     1\n",
      "23   1895                     1\n",
      "24   1896                     1\n",
      "25   1897                     1\n",
      "26   1898                     2\n",
      "27   1899                     3\n",
      "144  1900                     0\n",
      "28   1901                     1\n",
      "145  1902                     0\n",
      "29   1903                     3\n",
      "30   1904                     1\n",
      "31   1905                     2\n",
      "32   1906                     1\n",
      "33   1907                     4\n",
      "34   1908                     3\n",
      "35   1909                     4\n",
      "36   1910                     1\n",
      "146  1911                     0\n",
      "37   1912                     2\n",
      "147  1913                     0\n",
      "38   1914                     2\n",
      "39   1915                     2\n",
      "40   1916                     1\n",
      "41   1917                     3\n",
      "42   1918                     1\n",
      "43   1919                     2\n",
      "44   1920                     1\n",
      "45   1921                     5\n",
      "46   1922                     5\n",
      "47   1923                     1\n",
      "48   1924                     1\n",
      "148  1925                     0\n",
      "49   1926                     1\n",
      "50   1927                     2\n",
      "51   1928                     2\n",
      "52   1929                     2\n",
      "149  1930                     0\n",
      "53   1931                     1\n",
      "150  1932                     0\n",
      "151  1933                     0\n",
      "54   1934                     1\n",
      "55   1935                     4\n",
      "56   1936                     2\n",
      "152  1937                     0\n",
      "57   1938                     1\n",
      "58   1939                     1\n",
      "153  1940                     0\n",
      "154  1941                     0\n",
      "155  1942                     0\n",
      "59   1943                     1\n",
      "156  1944                     0\n",
      "157  1945                     0\n",
      "158  1946                     0\n",
      "159  1947                     0\n",
      "160  1948                     0\n",
      "161  1949                     0\n",
      "162  1950                     0\n",
      "163  1951                     0\n",
      "164  1952                     0\n",
      "165  1953                     0\n",
      "166  1954                     0\n",
      "60   1955                     1\n",
      "167  1956                     0\n",
      "168  1957                     0\n",
      "169  1958                     0\n",
      "170  1959                     0\n",
      "171  1960                     0\n",
      "172  1961                     0\n",
      "173  1962                     0\n",
      "174  1963                     0\n",
      "175  1964                     0\n",
      "176  1965                     0\n",
      "177  1966                     0\n",
      "178  1967                     0\n",
      "179  1968                     0\n",
      "180  1969                     0\n",
      "61   1970                     1\n",
      "181  1971                     0\n",
      "182  1972                     0\n",
      "183  1973                     0\n",
      "184  1974                     0\n",
      "185  1975                     0\n",
      "186  1976                     0\n",
      "187  1977                     0\n",
      "188  1978                     0\n",
      "189  1979                     0\n",
      "190  1980                     0\n",
      "191  1981                     0\n",
      "192  1982                     0\n",
      "62   1983                     1\n",
      "193  1984                     0\n",
      "63   1985                     1\n",
      "194  1986                     0\n",
      "195  1987                     0\n",
      "196  1988                     0\n",
      "197  1989                     0\n",
      "198  1990                     0\n",
      "199  1991                     0\n",
      "200  1992                     0\n",
      "201  1993                     0\n",
      "202  1994                     0\n",
      "203  1995                     0\n",
      "204  1996                     0\n",
      "205  1997                     0\n",
      "206  1998                     0\n",
      "207  1999                     0\n",
      "208  2000                     0\n",
      "64   2001                     1\n",
      "209  2002                     0\n",
      "210  2003                     0\n",
      "65   2004                     2\n",
      "66   2005                     1\n",
      "211  2006                     0\n",
      "212  2007                     0\n",
      "67   2008                     1\n",
      "213  2009                     0\n",
      "68   2010                     1\n",
      "69   2011                     1\n",
      "214  2012                     0\n",
      "215  2013                     0\n",
      "216  2014                     0\n",
      "217  2015                     0\n",
      "218  2016                     0\n",
      "70   2017                     1\n",
      "71   2018                     1\n",
      "219  2019                     0\n"
     ]
    }
   ],
   "source": [
    "neue_jahre = []\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv('ZeitromanDLAplusGBV_automatisch_gefiltert_und_manuell_bereinigt.csv', delimiter=';', lineterminator='\\n')\n",
    "df_counts = df.groupby(['date']).size().reset_index(name='Untertitel.Zeitroman')\n",
    "\n",
    "for x in range(1800, 2020):\n",
    "    if x not in df_counts[\"date\"].values:\n",
    "        #df_new = pd.DataFrame({\"date\":[x], \"counts\":[0]}) \n",
    "        neue_jahre.append({\"date\":x, \n",
    "                    \"Untertitel.Zeitroman\":0})\n",
    "    else:\n",
    "        pass\n",
    "df_new = pd.DataFrame(neue_jahre)\n",
    "df_counts = df_counts.append(df_new, ignore_index = True).sort_values(by='date')\n",
    "df_counts = df_counts.rename(columns = {'date':'Jahr'}).sort_values(by='Jahr')\n",
    "print(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts.reset_index()[['Jahr', 'Untertitel.Zeitroman']].to_csv('Untertitel_Zeitroman_Jahr.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
